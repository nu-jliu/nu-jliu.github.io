---
layout: post
title:  "Pick and Place with Ridheback-Sawyer-PX100 Robot"
categories: [ ROS1, Linux, Bash Shell, C++, Python, MoveIt!, Navigation, Rethink Sawyer Robot Arm, Interbotix PincherX-100 Robot Arm, Clearpath Ridgeback Mobile Platform ]
image: assets/images/sawback.gif
featured: true
hidden: true
---


ROS1, ROS Noetic, Linux, Bash Shell, C++, Python, Moveit!, Navigation, Rethink Sawyer Robot Arm, Interbotix PincherX-100 Robot Arm, Clearpath Ridgeback Mobile Platform

[View This Project on GitHub](https://github.com/nu-jliu/Winter_Project.git)

[Sawyer MoveIt!](https://github.com/nu-jliu/sawyer_moveit/tree/allen/Winter_project)

[Intera SDK](https://github.com/nu-jliu/intera_sdk/tree/allen/Winter_Project)

# Description
This project aims for implementing a `pick-and-place` pipline on a mobile manipulator via `ROS Noetic`, which is a `Clearpath Ridgeback Mobile Platform` with `Rethink Sawyer Robot Arm` and `Interbotix PincherX-100 Robot Arm mounted on top of it`.

<!-- `TODO: Add A Figure` -->

![](https://github.com/nu-jliu/Winter_Project/blob/main/sawback.png?raw=true)

# System Architecture

The overall system architecture integrates three primary subsystems to enable coordinated mobile manipulation.

```mermaid
graph TB
    subgraph UI["User Interface"]
        USER[User Commands]
        RVIZ[RViz Visualization]
    end

    subgraph Command["Command Interface"]
        PARSER[Goal Parser]
        COORD[Task Coordinator]
    end

    subgraph ArmControl["Robot Arm Control<br/>Rethink Sawyer"]
        MOVEIT[MoveIt! Planner]
        ARM_CTRL[Intera SDK Controller]
        SAWYER[Sawyer Arm]
    end

    subgraph BaseControl["Mobile Platform Control<br/>Clearpath Ridgeback"]
        NAV[ROS Navigation Stack]
        BASE_CTRL[Ridgeback Controller]
        MOBILE[Mobile Base]
    end

    subgraph Vision["Vision System<br/>Interbotix PX100"]
        CAM[RealSense Camera]
        PX100[PX100 Arm]
        DETECT[Object Detection]
    end

    USER --> PARSER
    PARSER --> COORD
    COORD --> MOVEIT
    COORD --> NAV
    MOVEIT --> ARM_CTRL
    ARM_CTRL --> SAWYER
    NAV --> BASE_CTRL
    BASE_CTRL --> MOBILE
    CAM --> DETECT
    DETECT --> COORD
    PX100 --> COORD

    SAWYER --> RVIZ
    MOBILE --> RVIZ

    style COORD fill:#fff4e1
    style MOVEIT fill:#e1f5ff
    style NAV fill:#d4edda
```

**Key Subsystems:**
 - **Robot Arm Control**: Controls the Sawyer robot arm motion using MoveIt! for motion planning and the Intera SDK for execution
 - **Mobile Platform Control**: Manages Ridgeback mobile base navigation using the ROS Navigation stack
 - **Command Interface**: Receives user goals, coordinates task execution between arm and base controllers
 - **Vision System**: PX100 arm with RealSense camera for object detection and localization

Original system diagram:
![](/assets/images/sawback_system.png)

## Software Workflow

### Pick Operation

```mermaid
sequenceDiagram
    participant User
    participant Vision
    participant Navigator
    participant Base
    participant Planner
    participant Arm

    User->>Vision: Select target object
    Vision->>Vision: Detect object pose
    Vision->>Navigator: Send target coordinates

    Navigator->>Navigator: Compute base goal pose
    Navigator->>Base: Navigate to position
    Base->>Base: Move to target location

    Base->>Planner: Base at goal, request grasp
    Planner->>Planner: Compute arm trajectory
    Planner->>Arm: Execute pick motion
    Arm->>Arm: Approach object
    Arm->>Arm: Close gripper (grasp)
    Arm->>Arm: Lift object

    Arm-->>User: Pick complete
```

The user selects a target object, the Ridgeback navigates to the appropriate position, and the Sawyer arm executes the pick motion.

Original pick workflow:
![](/assets/images/pick_sawback.png)

### Place Operation

```mermaid
flowchart TD
    START([Object Grasped]) --> INPUT[User specifies<br/>placement location]
    INPUT --> NAV_PLAN[Compute navigation path]
    NAV_PLAN --> MOVE[Ridgeback navigates<br/>to drop-off zone]

    MOVE --> ARM_PLAN[Plan placement trajectory]
    ARM_PLAN --> APPROACH[Arm approaches<br/>placement pose]
    APPROACH --> OPEN[Open gripper]
    OPEN --> RELEASE[Release object]

    RELEASE --> RETRACT[Retract to safe pose]
    RETRACT --> END([Place complete])

    style START fill:#d4edda
    style END fill:#d4edda
    style MOVE fill:#e1f5ff
    style ARM_PLAN fill:#fff4e1
```

Original place workflow:
![](/assets/images/place.drawio.png)

## Hardware
The overall hardware structure is shown in the figure below, which is a sawyer arm and a px100 arm with a realsense cammera attached mounted on the top of the ridgeback. 

## Network Architecture

The distributed computing system spans three networked machines for coordinated control.

```mermaid
graph TB
    subgraph PC["User PC"]
        UI[User Interface<br/>RViz + Command Line]
    end

    subgraph Ridgeback["Ridgeback Onboard Computer"]
        MASTER[ROS Master]
        NAV_NODE[Navigation Stack]
        COORD_NODE[Coordinator Node]
        BASE_DRIVER[Ridgeback Driver]
        PX100_DRIVER[PX100 Driver]
    end

    subgraph Sawyer["Sawyer Onboard Computer"]
        INTERA[Intera SDK]
        ARM_DRIVER[Sawyer Controller]
        ARM_STATE[Joint State Publisher]
    end

    UI <-->|ROS Network| MASTER
    MASTER <--> NAV_NODE
    MASTER <--> COORD_NODE
    MASTER <--> BASE_DRIVER
    MASTER <--> PX100_DRIVER

    MASTER <-->|ROS Network| INTERA
    INTERA <--> ARM_DRIVER
    ARM_DRIVER <--> ARM_STATE

    style PC fill:#e1f5ff
    style Ridgeback fill:#fff4e1
    style Sawyer fill:#d4edda
```

**System Components:**
 - **PC**: User control interface for sending commands and visualization via RViz
 - **Ridgeback Computer**: Hosts ROS Master, performs navigation calculations, coordinates system behavior
 - **Sawyer Computer**: Executes Intera SDK for arm control based on commands from Ridgeback computer

Original network diagram:
![](/assets/images/network.png)

## ROS
Based on the `ROS1` standard, in order for all nodes to be discovered by others, the `ROS_MASTER_URI` must be set to be the same, so that all nodes are running under the same `ROS master`. So that all parameters and topics are served on the same server so that they can listen to others.

### Packages
 - `motion_control`: Used the `ROS Navigation` to control the motion of the mobile platform.
 - `arm_control`: ontrol the motion of the robot arm.
 - `vision_control`: Calibrate the camera and control the motion of the `px100` arm.
 - `object_detection`: Used for detect target pose as for the target object.
 - `picker_interfaces`: Customized interfaces for transporting data between `ROS` nodes
 - `manipulator_description`: Visualizing the robot over `rviz`.


<!-- ## Frames -->

# Final Result

<iframe width="560" height="315" src="https://www.youtube.com/embed/G6C1wfTlVRs?si=QuOxMdutTlqjoj_H&amp;controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<!-- `TODO:` -->

# Technical Challenges

## `Moveit!` with Sawyer
The default `Moveit!` interface configuration for `sawyer` was not compatible with the current configuration of the robot since the robot arm is mounted on the base instead of mounting on the control algorith coming along with the software.

<!-- ## ROS Navigation -->


## Sawyer Hardware
There was a lot of issue setting up the `Rethink Sawyer` robot arm, there was some both mechanical and software issue for fixing it. 

Link: [Fixing Sawyer Arm](https://nu-jliu.github.io/sawyer/)

## Low Bandwidth
The robot is configured to use a 2G wifi to communicate with the laptop, making it difficult to transport large amount of data within short period of time. Which increases the latency between sensor and when data is processed. This will cause inacuracy on SLAM, path planning and motion planning. 