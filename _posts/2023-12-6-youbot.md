---
layout: post
title:  "Feedback Control on KUKA youBot"
categories: [ MATLAB, Robot Dynamics, Feedback Control, Feedforward Control, Mobile Manipulator ]
image: assets/images/youbot.gif
featured: false
hidden: false
---

MATLAB, Robot Dynamics, Feedback Control, Feedforward Control, Mobile Manipulator

**Authors**: Allen Liu

# Project Description
This project is to implement the feedforward/feedback control over the KUKA youBot to pick up a cube and place it at another place in the world.

# Goal
The goal of this project is to find the propotional gain $K_p$ and integral gain $K_i$ at 3 given scenarios: `Best`, `Overshoot` and `New Task`

## Best
For the `Best` controller, the target is to design the controller that robot follows the planned path perfectly without any oscillation.

## Overshoot
The `Overshoot` controller is designed to follow the planned path, but oscillates around the planned path.

## New Task
The `New Task` is the same as the `Best` controller, the goal of the `New Task` is different than the `Best`

# Features

## Translate from Chinese to English
<iframe width="560" height="315" src="https://www.youtube.com/embed/EdNptTr9Y0U?si=ZA9z5NeRokLx9CQw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Translate from German to French
<iframe width="560" height="315" src="https://www.youtube.com/embed/iFoNAHWQ9wE?si=es4q5_6K3KzxVzFM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Translate from Spanish to Korean
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qjd3jGlU8Ds?si=3aTC0FWY6vf4mSaL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Translate from Simpified Chinese to Traditional Chinese 
<iframe width="560" height="315" src="https://www.youtube.com/embed/9GdGPy74Qwg?si=FwCUxvQhKl4Oi-Fo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Hindi Voice to English
<iframe width="560" height="315" src="https://www.youtube.com/embed/BeQzYUYSe5k?si=6rlJjthlDPSmCw-F" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Spanish Voice to English
<iframe width="560" height="315" src="https://www.youtube.com/embed/9PCf_-gbIbU?si=YZCxg8eNQXIZg_Oy" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

# Challenges
1. *Cartesian Path Planner*: When first implementing the `find cartesian path` feature over `moveit` API, we faced the issue where the `rviz` showed that robot already found the path, but just not be able to execute it. So we looked through our code for the `moveit` API on the function that calls the `ComputeCartesianPath` service. And compare that with the official documentation for the moveit and then we found that me have a missing parameter called `cartesian_speed_limit_link` that we have not specified. Eventually after we fill in that blank, the robot moves as expected.
2. *TF tree when integrating apriltags*: When we first implemented the `apriltags` on the robot, we experienced some issue that sometimes the robot does not move as intended, that moving towards the orientation and position that will cause the collision. We started debug by examing the TF tree of the robot and did a lot experiments sending various command telling robot to move in all possible directions. And finally when we are examing the TF tree for the robot, we realize that as `apriltags` are added to the system, the root frame of the TF tree became the `camera` instead of the `panda_link0`, which is the base frame of the robot. So that the command we are sending is relaive to the `camera` frame instead of base frame. After we fix that, the robot moves perfectly.

# Possible improvements.
 - Some script language still fail to detect.
 - Sometimes, the camera source get dropped, need to re-launch all.